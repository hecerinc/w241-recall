---
title: "How do different audio stimuli affect cognitive function?"
author: "Laura Cheng, Eda Kavlakoglu, Liz Nichols, Hector Rincon"
date: "W241 Experiments and Causal Inference - Spring 2022"
output:
  bookdown::pdf_document2: 
    number_sections: yes
    fig_caption: yes
  word_document: default
---


```{r package loads, warning=FALSE, message=FALSE, include=FALSE}
library(data.table)
library(sandwich)
library(lmtest)
library(ggplot2)
library(knitr)
library(patchwork)
library(stargazer)
install.packages("vtable")
library(vtable)
library(grid)
library(gridExtra)
```

```{r data clean up, include = FALSE}
load('../data/processed/survey_data_clean_20220410.RData')
d <- data.table(x)

# Remove the ones that have no Q12 data (missing data)
d <- d[q12.score != 0,]

# TODO: check this (attrition?). Limit the results to answers that have something for Q25
d[q25.score == 0, ]
d[is.na(posttask.time),]
# These two above are *not* the same, I'm gonna keep the ones that are finished (2/7). The other 5/7 have no time spent in Q25 so we're good removing those.
d <- d[!is.na(posttask.time),]
```

```{r models}

```


```{r}

```


\tableofcontents
\newpage

# Introduction

In this paper, we explore the impact of four audio stimuli of varying emotional effect on cognitive function. More specifically, does negative audio stimuli impair cognitive performance compared to positive and neutral ones? Using a difference-in-differences (`DID`) experiment design in Qualtrics, participants completed a baseline memorization task, then were randomly assigned to a stimuli and asked to complete a second memorization task after. 

We found that there was no statistically significant effect of negative stimuli on cognitive function. We acknowledge as well that the negative stimuli used in this experiment may not have been strong enough to create a treatment effect, and also that treatment may need to be repeated over time to detect an effect. 

## Prior Research

Previous studies have tested the impact of various audio content with varying results. For example, when we explore meditation as a positive treatment and its effects on cognition, results have demonstrated reductions in mind-wandering, leading to improvements in GRE reading comprehension scores ^[https://pubmed.ncbi.nlm.nih.gov/23538911/]. In other studies, researchers found that it had also been connected to increases in left hippocampal volume in the brain as well as working and recognition memory performance ^[https://www.sciencedirect.com/science/article/abs/pii/S016643281830322X]. However, many of these experiments were conducted over multiple week periods, not as a single exposure study.

While there is stronger evidence of positive effects on cognitive performance for meditative content, the results are less conclusive for more negative content, such as shocking news–i.e. announcements related to wars, school shootings, pandemics, et cetera. A Finland study conducted a `DID` analysis to understand the impact of school shootings on a national high school examination and found that test scores dropped by 4.3 percentage points among males only ^[https://www.sciencedirect.com/science/article/pii/S0176268016301768]. That said, there are many stressors that a group of males can undergo over the year period between examinations, and it may be impractical to conclude that one traumatic event can have such a long-term effect on only one sex. 

In another study, researchers conducted an experiment around news exposure among older adults, which showed no effect on stress or cognitive function ^[https://journals.sagepub.com/doi/abs/10.1177/0091415017729684]. While there’s evidence of negative effects on cognitive functioning from direct trauma ^[https://link.springer.com/article/10.1186/1471-2377-10-61], such as the various forms of abuse, the indirect impact of alarming incidents is more unclear. 

Repeated exposure to negative content may be necessary to see a significant impairment on cognition, however this experiment seeks to measure the extent to which users underperform on memory tasks after a single exposure to negative stimuli compared to that of positive and neutral ones. Based on previous literature, we hypothesize that a negative stimulus will lead to worse cognitive performance while a positive stimulus will improve it. We also expect that our neutral stimulus should perform about the same as the control group.


## Recruitment

Our audio content experiment began and concluded in April 2022. Participants were recruited through word of mouth sharing with friends, family and other University of California, Berkeley students in addition to incentivized recruitment through Mechanical Turk. Because we recruited participants without respect to geographic location, we included a question in the first section of the survey to determine whether English is the participant's native language. This allowed us to include a covariate to account for any potential bias resulting from an unaccounted disadvantage, as the memorization task used English words.


\newpage

# Experimental Design

## Survey Design
We conducted the experiment using Qualtrics which allowed us to create a custom survey (Figure \@ref(fig:design)). The survey started with a pre-treatment question block asking for the participant's consent to data collection and demographic data, such as age range, gender, education, and English as a first language, as covariates to include in the analysis. If the user did not consent to participate, they immediately exited the experiment. Blocking was implemented by age range as we anticipated the results from older participants could create more variance given that memory can deteriorate with age. 


```{r design, echo=FALSE, fig.cap="Experimental Design Diagram", out.width = '75%', fig.align='center'}
# to adjust the caption, edit fig.cap above
knitr::include_graphics("design.png")
```


Each participant was then prompted to complete a pre-treatment memory recognition task, where 30 words were shown for a period of one minute (Figure \@ref(fig:instructions)). Following exposure to this random list of words (sourced from random.org), participants were then given 30 seconds to select the words that they recognized from another list of 50 (Figure \@ref(fig:task)). The results from this task provided a baseline for cognitive performance. Within each block, participants were then randomly assigned to one of four groups–control, positive, neutral, and negative. After exposure to the treatment, participants were asked to complete another memory recognition task with a different set of 30 words. 


```{r instructions, echo=FALSE, fig.cap="Instructions in Survey", out.width = '75%', fig.align='center'}
# to adjust the caption, edit fig.cap above
knitr::include_graphics("instructions.png")
```

```{r task, echo=FALSE, fig.cap="Memorization Task in Survey", out.width = '75%', fig.align='center'}
# to adjust the caption, edit fig.cap above
knitr::include_graphics("task.png")
```

## Treatment Descriptions

All treatments contained an audio file, which was around five minutes in length. The control group received an audio of white noise and the positive treatment group listened to a meditation from Headspace. The neutral and negative treatment groups were each given a 5 minute podcast; one was on the science of finger snapping and the other was focused on the tragedies of the Ukraine War. See Figure \@ref(fig:treatments).


```{r treatments, echo=FALSE, fig.cap="Treatments and Control", out.width = '50%', fig.align='center'}
# to adjust the caption, edit fig.cap above
knitr::include_graphics("data_def.png")
```



## Outcome Variables

Cognitive outcomes in this experiment were primarily measured by the number of words correctly recognized. While we also measured the length of time users took to complete this memory task, we did not expect many users to finish before the allotted 30 second time period.   

## ROXO methodology

Our experiment used a blocked difference-in-differences (DID) methodology, which can be illustrated with the following notation within each block:

R O Y O Y
R O Y X Y
R O Y X Y
R O Y X Y

The DID plots below illustrate the subtle differences across each treatment compared to control and its counterfactual. 

```{r}
#set up data for DID plots
scores_treatment <- d[ ,.(pre_treat_scores = mean(q12.score), post_treat_scores=mean(q25.score)), by = (treatment)]

scores_1 <- d[ ,.(score = mean(q12.score)), by = (treatment)]
observation <- c("pre-treatment", "pre-treatment", "pre-treatment", "pre-treatment")
final_scores_1 <- cbind(observation, scores_1)
final_scores_1

scores_2 <- d[ ,.(score = mean(q25.score)), by = (treatment)]
observation <- c("post-treatment", "post-treatment", "post-treatment", "post-treatment")
final_scores_2 <- cbind(observation, scores_2)
final_scores_2 

scores <- rbind(final_scores_1, final_scores_2)
scores

# Treatment group (Positive) before treatment
pos_pre <- scores_treatment[3,2]
pos_pre

# Treatment group (Positive) after treatment
pos_post <- scores_treatment[3,3]
pos_post

# Treatment group (Negative) before treatment
neg_pre <- scores_treatment[4,2]
neg_pre

# Treatment group (Negative) after treatment
neg_post <- scores_treatment[4,3]
neg_post

# Treatment group (Negative) before treatment
neutral_pre <- scores_treatment[2,2]
neutral_pre

# Treatment group (Negative) after treatment
neutral_post <- scores_treatment[2,3]
neutral_post

# Control group (white noise) before treatment
ctrl_pre <- scores_treatment[1,2]

# Control group (white) after treatment
ctrl_post <- scores_treatment[1,3]

# Calculate counterfactual outcome (positive)
pos_counterfactual <- tibble(
  observation = c("pre-treatment","post-treatment"), 
  treatment = c("positive (counterfactual)","positive (counterfactual)"),
  score = as.numeric(c(pos_pre, pos_pre-(ctrl_pre-ctrl_post))))

# Calculate counterfactual outcome (neutral)
neutral_counterfactual <- tibble(
  observation = c("pre-treatment","post-treatment"), 
  treatment = c("neutral (counterfactual)","neutral (counterfactual)"),
  score = as.numeric(c(neutral_pre, neutral_pre-(ctrl_pre-ctrl_post))))

# Calculate counterfactual outcome (negative)
neg_counterfactual <- tibble(
  observation = c("pre-treatment","post-treatment"), 
  treatment = c("negative (counterfactual)","negative (counterfactual)"),
  score = as.numeric(c(neg_pre, neg_pre-(ctrl_pre-ctrl_post))))

# Data points for treatment event
intervention_pos <- tibble(
    observation = c("intervention", "intervention", "intervention"),
    treatment = c("positive", "control", "positive (counterfactual)"), 
    score = c(13.805, 11.0175, 13.805)
  ) 

intervention_neutral <- tibble(
    observation = c("intervention", "intervention", "intervention"),
    treatment = c("neutral", "control", "neutral (counterfactual)"), 
    score = c(10.39, 11.0175, 10.38)
  ) 

intervention_negative <- tibble(
    observation = c("intervention", "intervention", "intervention"),
    treatment = c("negative", "control", "negative (counterfactual)"), 
    score = c(9.05, 11.0175, 9.051)
  ) 

#Combine data (pos)
scores_pos <- filter(scores, treatment == "positive" | treatment == "control")

did_plotdata_pos <- bind_rows(scores_pos, 
                          pos_counterfactual,
                          intervention_pos
                          )

#combine data (neutral)
scores_neutral <- filter(scores, treatment == "neutral" | treatment == "control")

did_plotdata_neutral <- bind_rows(scores_neutral, 
                          neutral_counterfactual,
                          intervention_neutral
                          )

#combine data (negative)
scores_negative <- filter(scores, treatment == "negative" | treatment == "control")

did_plotdata_negative <- bind_rows(scores_negative, 
                          neg_counterfactual,
                          intervention_negative
                          )
```

```{r}
#pos did plot

pos_did_plot <- did_plotdata_pos %>%
  mutate(label = if_else(observation == "post-treatment", as.character(treatment), NA_character_)) %>%
  ggplot(aes(x=observation,y=score, group=treatment)) +
  scale_x_discrete(limits = c("pre-treatment", "intervention", "post-treatment"))+
  geom_line(aes(color=treatment), size=1.2) +
  geom_vline(xintercept = "intervention", linetype="dotted", 
             color = "black", size=1.1) + 
  scale_color_brewer(palette = "Accent") +
  scale_y_continuous(limits = c(9, 17)) +
  ggrepel::geom_label_repel(aes(label = label),
                   nudge_x = 0.5, nudge_y = -0.5,
                   na.rm = TRUE) +
  guides(color="none") +
  labs(x="", y="score (mean)") +
  annotate(
    "text",
    x = "post-treatment",
    y = 12,
    label = "{Difference-in-Differences}",
    angle = 90,
    size = 3
  )

#neutral did plot

neutral_did_plot <- did_plotdata_neutral %>%
  mutate(label = if_else(observation == "post-treatment", as.character(treatment), NA_character_)) %>%
  ggplot(aes(x=observation,y=score, group=treatment)) +
  scale_x_discrete(limits = c("pre-treatment", "intervention", "post-treatment"))+
  geom_line(aes(color=treatment), size=1.2) +
  geom_vline(xintercept = "intervention", linetype="dotted", 
             color = "black", size=1.1) + 
  scale_color_brewer(palette = "Accent") +
  scale_y_continuous(limits = c(9, 12)) +
  ggrepel::geom_label_repel(aes(label = label),
                   nudge_x = 0.5, nudge_y = -0.5,
                   na.rm = TRUE) +
  guides(color="none") +
  labs(x="", y="score (mean)") +
  annotate(
    "text",
    x = "post-treatment",
    y = 10.5,
    label = "{Difference-in-Differences}",
    angle = 90,
    size = 3
  )

#neg did plot

neg_did_plot <-did_plotdata_negative %>%
  mutate(label = if_else(observation == "post-treatment", as.character(treatment), NA_character_)) %>%
  ggplot(aes(x=observation,y=score, group=treatment)) +
  scale_x_discrete(limits = c("pre-treatment", "intervention", "post-treatment"))+
  geom_line(aes(color=treatment), size=1.2) +
  geom_vline(xintercept = "intervention", linetype="dotted", 
             color = "black", size=1.1) + 
  scale_color_brewer(palette = "Accent") +
  scale_y_continuous(limits = c(8, 12.5)) +
  ggrepel::geom_label_repel(aes(label = label),
                   nudge_x = 0.5, nudge_y = -0.5,
                   na.rm = TRUE) +
  guides(color="none") +
  labs(x="", y="score (mean)") +
  annotate(
    "text",
    x = "post-treatment",
    y = 12,
    label = "{Difference-in-Differences}",
    angle = 90,
    size = 3
  )

library(cowplot)
plot_grid(pos_did_plot, neutral_did_plot,  neg_did_plot, labels = "AUTO")
```

## Covariates



* VIZ: covariate balance check
```{r}
#count of respondents
respondent_cnt <- setorder(d[ , count := .N, by = .(age =age.demographic, treatment)])
respondent_cnt 

#plot grouped bar charts

ggplot(respondent_cnt, aes(fill=treatment, y=count, x=age.demographic, color=treatment)) + 
    labs ( title = "Respondent Count by Age Group and Treatment",
             x = "age group")+ 
    geom_bar(position="dodge", alpha = 0.6, stat="identity")
```
```{r, echo = FALSE, fig.cap = "Plots of Age Group Distributions By Covariates"}
p1 <- ggplot(d, aes(x=gender, fill = age.demographic)) +
  geom_bar(position="stack")
p1 <- p1 + theme(axis.text.x = element_text(angle = 25, hjust = 1))
p2 <- ggplot(d, aes(x=highest.education, fill = age.demographic)) +
  geom_bar(position="stack")
p2 <- p2 + theme(axis.text.x = element_text(angle = 30, hjust = 1))
p3 <- ggplot(d, aes(x=english.native, fill = age.demographic)) +
  geom_bar()
grid.arrange(p1,p2,p3, ncol=2, top = "Covariate Distributions")
```
Most of our survey participants fell within the age groups of 18-30 and 30-40. Between our covariates, highest education was the covariate with the most variance across all participants. We then investigated the covariate balance across treatment groups in the age group blocks for education level.

```{r, echo = FALSE, fig.cap ="Plots of Highest Education Distribution by Treatment and Age Group"}
p_distribution4 <- ggplot(d[age.demographic=="18-30",], aes(x=treatment, fill=highest.education)) + geom_bar(position="stack") + ggtitle("Age Group: 18-30") + theme(plot.title = element_text(size=10)) + theme(axis.text.x = element_text(angle = 25, hjust = 1)) + theme(legend.key.size = unit(0.2, "cm"))
p_distribution5 <- ggplot(d[age.demographic=="30-40",], aes(x=treatment, fill=highest.education)) + geom_bar(position="stack") + ggtitle("Age Group: 30-40") + theme(plot.title = element_text(size=10)) + theme(axis.text.x = element_text(angle = 25, hjust = 1)) + theme(legend.key.size = unit(0.2, "cm"))
p_distribution6 <- ggplot(d[age.demographic=="40-50",], aes(x=treatment, fill=highest.education)) + geom_bar(position="stack") + ggtitle("Age Group: 40-50") + theme(plot.title = element_text(size=10)) + theme(axis.text.x = element_text(angle = 25, hjust = 1)) + theme(legend.key.size = unit(0.2, "cm"))
p_distribution7 <- ggplot(d[age.demographic=="50-60"], aes(x=treatment, fill=highest.education)) + geom_bar(position="stack") + ggtitle("Age Group: 50-60") + theme(plot.title = element_text(size=10)) + theme(axis.text.x = element_text(angle = 25, hjust = 1)) + theme(legend.key.size = unit(0.2, "cm"))
p_distribution8 <- ggplot(d[age.demographic=="60+"], aes(x=treatment, fill=highest.education)) + geom_bar(position="stack") + ggtitle("Age Group: 60+") + theme(plot.title = element_text(size=10)) + theme(axis.text.x = element_text(angle = 25, hjust = 1)) + theme(legend.key.size = unit(0.2, "cm"))

grid.arrange(p_distribution4,p_distribution5,p_distribution6,p_distribution7, p_distribution8, ncol=2, top = "Covariate Distributions by Age Group: Highest Education")
```
The plot above shows that across treatment and control groups with ample sample size, education is evenly distributed within our experiment.

\newpage
# Power Analysis

```{r flowchart, echo=FALSE, fig.cap="Participant Random Assignment Flow Chart", out.width = '50%', fig.align='center'}
# to adjust the caption, edit above
knitr::include_graphics("flowchart.png")
```

```{r, echo=FALSE}
power.t.test(n= NULL, delta = 1, sd = 1, sig.level = 0.05, power = 0.8, type = "two.sample", alternative = "one.sided")
```


Prior to the experiment, we estimated a DID effect of 1 additional word correctly or incorrectly guessed between treatment and control with a standard deviation of 1, aiming for a power of 0.8. This would require at least 14 subjects in each treatment and control group to achieve.


\newpage
# Data Analysis

* VIZ: DID line plot


## Attrition

In this experiment, attrition was defined as any individual who completed the first memory recognition task, but not the second one.

```{r truth table, echo=FALSE, fig.cap="Data Definitions for Completion and Attrition"}

dt <- data.frame( n = c("Missing Data", "Missing Data", "Attrition","Complete Data"),
                  r = c("No", "No", "Yes","Yes"),
                  c = c("No", "Yes","No", "Yes")
)

colnames(dt) <- c("Data Definitions","Completed First Memory Task","Completed Second Memory Task")

knitr::kable(dt)
# why isn't the fig caption showing up??
```

```{r, echo=FALSE, fig.cap = "Plot of Attrition by Age and Treatment"}
#Creating a status column in the original data set based on the previous truth table
d[, status := ifelse((q12.score != 0 & q25.score == 0 & finished == 0) | (finished == 1 & q12.score != 0 & q25.score == 0), "attritted", ifelse((q12.score == 0 & q25.score == 0) | (q12.score == 0 & q25.score != 0), "missing_data", "complete"))]

#Showing attrition visually
p_attrition1 <- ggplot(data, aes(x=age.demographic, fill = status)) +
  geom_bar(position="dodge")
p_attrition2 <- ggplot(data, aes(x= treatment, fill = status)) +
  geom_bar(position="dodge")
grid.arrange(p_attrition1, p_attrition2, top = "Attrition by Age and Treatment Group")

```

Majority of participants completed the experiment fully, while there were several attritted participants in all treatment and control groups.

```{r, echo = FALSE, fig.cap = "Attrition P-Value Table"}
#Creating subsets
#Simple subset by treatment
data_att_simple = data[, .N, by='treatment']
#Subset by treatment AND complete/attrition/missing data status
data_att <- data[, .N, by=c('treatment', 'status')]
setorder(data_att, cols = 'treatment')
#data_att
#Even more subsetting including our age group blocking
data_att_age <- data[, .N, by=c('age.demographic','treatment', 'status')]
setorder(data_att_age, cols = 'age.demographic')
#data_att_age
#Including attrition/missing data, equally distributed!
res <- data_att_simple[, chisq.test(N, p=c(1/4,1/4,1/4,1/4))]
#res
#Taking into account attrition for entire experiment
res2 <- data_att[status == 'complete', chisq.test(N, p=c(1/4,1/4,1/4,1/4))]
#res2
#Now by age group!
#18-30
res3 <- data_att_age[status == 'complete' & age.demographic == '18-30' , chisq.test(N, p=c(1/4,1/4,1/4,1/4))]
#res3
#30-40
res4 <- data_att_age[status == 'complete' & age.demographic == '30-40' , chisq.test(N, p=c(1/4,1/4,1/4,1/4))]
#res4
#The rest give warning of "Chi-squared approximation may be incorrect"
#Makes sense since we have much less data in these age groups compared to younger than 40
#40-50
res5 <- data_att_age[status == 'complete' & age.demographic == '40-50' , chisq.test(N, p=c(1/4,1/4,1/4,1/4))]
#res5
#50-60
res6 <- data_att_age[status == 'complete' & age.demographic == '50-60' , chisq.test(N, p=c(1/4,1/4,1/4,1/4))]
#res6
#60+
res7 <- data_att_age[status == 'complete' & age.demographic == '60+' , chisq.test(N, p=c(1/4,1/4,1/4,1/4))]
#res7
#Creating attrition table of p values
data_att_p <- data.table(
  age.demographic = c('18-30','30-40', '40-50', '50-60', '60+'),
  p.value = c(res3$p.value,res4$p.value,res5$p.value,res6$p.value,res7$p.value)
)
data_att_p
```

We can see that in all treatment groups and the control group, even with the attritted participants removed, there is an even distribution of participants within the age group blocks.

\newpage
# Results

==HECTOR==

## Limitations


There are reasons to suspect that the assigned treatment influences outcomes for reasons other than the treatment that is actually delivered. Since we did not actively monitor users as they participate in this experiment we cannot be confident that every respondent engaged with the stimulus in the same manner. For example, participants may have multitasked during the audio treatment or they may have taken screenshots of the word list to memorize. 

Additionally, the different treatments may have been more engaging than others. For example, it may be harder for a participant to focus on a white noise control for a five minute duration, causing more users in this group to attrit. 

We also acknowledge participants could have "gamed" the experiment by selecting every single word in the recall list. The survey did not tell the participant if their selection was correct or not, which we intended to disincentivize this behavior. However, our scoring methodology did not penalize incorrect answers, so this could have had unintended consequences in our analysis. However, when we reviewed the data and included a penalty for incorrect answers, there were very few instances where the penalized score differed from the simple count score. 

In our survey design we also made one mistake, creating overlapping age groups for 30-40 and 40-50. So for participants aged 40 may have been confused and declined to participate, or chose one age group inconsistently (i.e. some 40 year olds chose the younger group and others chose the older). 

Finally, the amount of time that we allotted to participants to complete the memory recognition task was likely problematic for our models where the task completion time was the outcome variable. Some participants reported that thirty seconds wasn't a sufficient amount of time to complete the task, and if the majority of participants felt this way, then this could have minimized a treatment effect within our results. Extending the task completion time in a future iteration would remove this limitation. 

\newpage
# Conclusion

\newpage
# References